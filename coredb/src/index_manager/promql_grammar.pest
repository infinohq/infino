//! PEG grammar for Query DSL
//! This grammar is whitespace-permissive.

// NOTES
// 1. There are implicit dependencies on grammar verification, for example the order
// of query rules or whether rules are AND'd or OR'd. The query code assumes this grammar
// is correct and the Pest parser validates the input before query code is executed. This is thus
// a brittle area of code since there we do not have unit tests for grammar verification.
// 
// 2. Parser error messages are not intuitive. If you have any problems parsing your input, copy
// this grammar into the live parser at https://pest.rs/ and debug with your json input.
// 
// 3. This grammar focuses on query syntax verification and is rewritten to avoid recursion.
// 
// 4. This grammar is intended to be compatible with Prometheus v2.45.0
// https://github.com/prometheus/prometheus/tree/v2.45.0
// 
// 5. See Prometheus docs here:
// https://prometheus.io/docs/prometheus/latest/querying/basics/
// 
// 6. We define expressions as a series of operations or terms that can be combined with binary operators
// - Compound expressions handle binary operations to avoid direct left recursion
// - Unary expressions apply a unary operator to any non-operation expression
// - Non-operation expressions are expressions that do not immediately involve binary or unary operations
// - Expressions can also have an offset modifier

start = { expression }

// Define an expression as a series of operations with increasing precedence
expression  = { logical_and ~ ((or | unless) ~ logical_and)* ~ subquery? }
logical_and = { equality ~ (and ~ equality)* }
equality    = { comparison ~ ((equal | not_equal) ~ comparison)* }
comparison  = { term ~ ((greater_than | less_than | greater_than_or_equal | less_than_or_equal) ~ term)* }
term        = { factor ~ ((plus | minus) ~ factor)* }
factor      = { exponent ~ ((multiply | divide | modulo) ~ exponent)* }
exponent    = { unary ~ (power ~ unary)* }
unary       = { negative? ~ leaf }
leaf        = { scalar | vector | aggregations | functions }

// *** Operations ***
or                    = { "or" }
and                   = { "and" }
unless                = { "unless" }
equal                 = { "==" }
not_equal             = { "!=" }
greater_than          = { ">" }
less_than             = { "<" }
greater_than_or_equal = { ">=" }
less_than_or_equal    = { ">=" }
plus                  = { "+" }
minus                 = { "-" }
multiply              = { "*" }
divide                = { "/" }
modulo                = { "%" }
power                 = { "^" }
negative              = { "-" }

// Aggregations
aggregations   = { aggregation ~ start_paren ~ ((group_modifier ~ vector ~ end_paren) | (vector ~ end_paren)) }
aggregation    = { sum | avg | max | min | count | count_values | quantile | stddev | stdvar | topk | bottomk | group }
group_modifier = { ("by" | "without") ~ start_brace ~ label_name ~ (comma ~ label_name)* ~ end_brace }

// Define individual rules for each aggregation type
sum          = { "sum" }
avg          = { "avg" }
max          = { "max" }
min          = { "min" }
count        = { "count" }
count_values = { "count_values" ~ label_name }
quantile     = { "quantile" }
stddev       = { "stddev" }
stdvar       = { "stdvar" }
topk         = { "topk" }
bottomk      = { "bottomk" }
group        = { "group" }

// **** Function calls ****
functions = { function ~ start_paren ~ (expression ~ (comma ~ expression)*)? ~ end_paren }
function  = { "abs" | "absent" | "absent_over_time" | "acos" | "acosh" | "asin" | "asinh" | "atan" | "atanh" | "avg_over_time" | "ceil" | "changes" | "clamp" | "clamp_max" | "clamp_min" | "cos" | "cosh" | "count_over_time" | "days_in_month" | "day_of_month" | "day_of_week" | "day_of_year" | "deg" | "delta" | "deriv" | "exp" | "floor" | "histogram_quantile" | "holt_winters" | "hour" | "idelta" | "increase" | "irate" | "label_replace" | "label_join" | "last_over_time" | "ln" | "log10" | "log2" | "max_over_time" | "min_over_time" | "minute" | "month" | "pi" | "predict_linear" | "present_over_time" | "quantile_over_time" | "rad" | "rate" | "resets" | "round" | "scalar" | "sgn" | "sin" | "sinh" | "sort" | "sort_desc" | "sqrt" | "stddev_over_time" | "stdvar_over_time" | "sum_over_time" | "tan" | "tanh" | "time" | "timestamp" | "vector" | "year" }

// **** Vector creation ****
scalar              = { float }
vector              = { metric_name ~ (start_brace ~ label ~ (comma ~ label)* ~ end_brace)? ~ range? ~ offset_and_modifier? }
label               = { label_name ~ condition ~ label_value }
condition           = { equal_match | not_equal_match | regex_match | not_regex_match }
offset              = { "offset" ~ duration }
modifier            = { "@" ~ float }
regex_match         = { "=~" }
not_regex_match     = { "!~" }
equal_match         = { equal }
not_equal_match     = { not_equal }
offset_and_modifier = { (offset ~ modifier?) | (modifier ~ offset?) }
range               = { (start_bracket ~ duration ~ end_bracket)? }
subquery            = { (start_bracket ~ duration ~ (colon ~ duration)? ~ end_bracket)? }

// **** Low-level semantic definitions ****
// _ prefix means silent; lets Pest know that these rules shouldn't create an AST node
// @ prefix means atomic; lets Pest know to create a single token (i.e. a string or a number) instead
metric_name    = @{ (ASCII_ALPHA | "_" | ":") ~ (ASCII_ALPHANUMERIC | "_" | ":")* }
colon          = _{ ws ~ ":" ~ ws }
comma          = _{ ws ~ "," ~ ws }
digits         = @{ ASCII_DIGIT+ }
duration       =  { digits ~ ("s" | "m" | "h" | "d" | "w" | "y") }
end_brace      = _{ ws ~ "}" ~ ws }
end_bracket    = _{ ws ~ "]" ~ ws }
end_paren      = _{ ws ~ ")" ~ ws }
escaped_char   = _{ "\"\\\"" ~ ("\"" | "\\" | "/" | "b" | "f" | "n" | "r" | "t" | unicode_escape) }
float          = @{ "-"? ~ (digits ~ "." ~ digits? | "." ~ digits) }
label_name     = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_")* }
label_value    =  { string }
normal_char    = _{ !("\"" | "\\") ~ ANY }
quote          = _{ "\"" }
start_brace    = _{ ws ~ "{" ~ ws }
start_bracket  = _{ ws ~ "[" ~ ws }
start_paren    = _{ ws ~ "(" ~ ws }
string         = @{ quote ~ (escaped_char | normal_char)+ ~ quote }
unicode_escape = @{ "\"u\"" ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT }
ws             = _{ (" " | "\t" | NEWLINE)* }
