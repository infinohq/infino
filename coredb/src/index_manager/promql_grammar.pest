//! PEG grammar for Query DSL
//! This grammar is whitespace-permissive.

// NOTES
// 1. There are implicit dependencies on grammar verification, for example the order
// of query rules or whether rules are AND'd or OR'd. The query code assumes this grammar
// is correct and the Pest parser validates the input before query code is executed. This is thus
// a brittle area of code since there we do not have unit tests for grammar verification.
// 
// 2. Parser error messages are not intuitive. If you have any problems parsing your input, copy
// this grammar into the live parser at https://pest.rs/ and debug with your json input.
// 
// 3. This grammar focuses on query syntax verification and is rewritten to avoid recursion.
// 
// 4. This grammar is intended to be compatible with Prometheus v2.45.0
// https://github.com/prometheus/prometheus/tree/v2.45.0
// 
// 5. See Prometheus docs here:
// https://prometheus.io/docs/prometheus/latest/querying/basics/
// 
// 6. We define expressions as a series of operations or terms that can be combined with binary operators
// - Compound expressions handle binary operations to avoid direct left recursion
// - Unary expressions apply a unary operator to any non-operation expression
// - Non-operation expressions are expressions that do not immediately involve binary or unary operations
// - Expressions can also have an offset modifier

start = { expression }

// Define an expression as a series of operations with increasing precedence
expression  = { logical_and ~ (binary_or ~ logical_and)* }
logical_and = { equality ~ (binary_and ~ equality)* }
equality    = { comparison ~ ((equal | not_equal) ~ comparison)* }
comparison  = { term ~ ((greater_than | less_than | greater_than_or_equal | less_than_or_equal) ~ term)* }
term        = { factor ~ ((plus | minus) ~ factor)* }
factor      = { exponent ~ ((multiply | divide | percent) ~ exponent)* }
exponent    = { unary ~ power? ~ integer }
unary       = { minus? ~ ((leaf ~ ("offset" ~ duration)?)) }
leaf        = { scalar | vector | subquery | aggregations | function_call }

// *** Operations ***
binary_or             = _{ "or" }
binary_and            = _{ "and" }
equal                 =  { "==" }
not_equal             =  { "!=" }
greater_than          =  { ">" }
less_than             =  { "<" }
greater_than_or_equal =  { ">=" }
less_than_or_equal    =  { ">=" }
plus                  =  { "+" }
minus                 =  { "-" }
multiply              =  { "*" }
divide                =  { "/" }
percent               =  { "%" }
power                 =  { "^" }

// Scalar values and vectors
scalar   = { float }
vector   = { metric_name ~ matchers? ~ (start_bracket ~ duration ~ end_bracket)? }
subquery = { vector ~ start_bracket ~ duration ~ (colon ~ duration)? ~ end_bracket }

// Aggregations
aggregations   = { aggregation ~ start_paren ~ ((group_modifier ~ vector ~ end_paren) | (vector ~ end_paren)) }
aggregation    = { sum | avg | max | min | count | count_values | quantile | stddev | stdvar | topk | bottomk | group }
group_modifier = { ("by" | "without") ~ start_brace ~ label_name ~ (comma ~ label_name)* ~ end_brace }

// Define individual rules for each aggregation type
sum          = { "sum" }
avg          = { "avg" }
max          = { "max" }
min          = { "min" }
count        = { "count" }
count_values = { "count_values" ~ label_name }
quantile     = { "quantile" }
stddev       = { "stddev" }
stdvar       = { "stdvar" }
topk         = { "topk" }
bottomk      = { "bottomk" }
group        = { "group" }

// **** Function calls ****
function_call = { function_name ~ start_paren ~ (expression ~ (comma ~ expression)*)? ~ end_paren }
function_name = { "abs" | "absent" | "absent_over_time" | "acos" | "acosh" | "asin" | "asinh" | "atan" | "atanh" | "avg_over_time" | "ceil" | "changes" | "clamp" | "clamp_max" | "clamp_min" | "cos" | "cosh" | "count_over_time" | "days_in_month" | "day_of_month" | "day_of_week" | "day_of_year" | "deg" | "delta" | "deriv" | "exp" | "floor" | "histogram_quantile" | "holt_winters" | "hour" | "idelta" | "increase" | "irate" | "label_replace" | "label_join" | "last_over_time" | "ln" | "log10" | "log2" | "max_over_time" | "min_over_time" | "minute" | "month" | "pi" | "predict_linear" | "present_over_time" | "quantile_over_time" | "rad" | "rate" | "resets" | "round" | "scalar" | "sgn" | "sin" | "sinh" | "sort" | "sort_desc" | "sqrt" | "stddev_over_time" | "stdvar_over_time" | "sum_over_time" | "tan" | "tanh" | "time" | "timestamp" | "vector" | "year" }

// **** Matchers ****
matchers       = { start_brace ~ matcher ~ (comma ~ matcher)* ~ end_brace }
matcher        = { label_name ~ match_operator ~ match_value }
match_operator = { "=" | "!=" | "=~" | "!~" }
match_value    = { string }

// **** Low-level semantic definitions ****
// _ prefix means silent; lets Pest know that these rules shouldn't create an AST node
// @ prefix means atomic; lets Pest know to create a single token (i.e. a string or a number) instead
metric_name    = @{ (ASCII_ALPHA | "_" | ":") ~ (ASCII_ALPHANUMERIC | "_" | ":")* }
colon          = _{ ws ~ ":" ~ ws }
comma          = _{ ws ~ "," ~ ws }
digits         = @{ ASCII_DIGIT+ }
duration       =  { digits ~ ("s" | "m" | "h" | "d" | "w" | "y") }
end_brace      = _{ ws ~ "}" ~ ws }
end_bracket    = _{ ws ~ "]" ~ ws }
end_paren      = _{ ws ~ ")" ~ ws }
escaped_char   = _{ "\"\\\"" ~ ("\"" | "\\" | "/" | "b" | "f" | "n" | "r" | "t" | unicode_escape) }
float          = @{ "-"? ~ (digits ~ "." ~ digits? | "." ~ digits) }
integer        = @{ "-"? ~ digits }
label_name     = @{ (ASCII_ALPHA | "_") ~ (ASCII_ALPHANUMERIC | "_")* }
normal_char    = _{ !("\"" | "\\") ~ ANY }
quote          = _{ "\"" }
start_brace    = _{ ws ~ "{" ~ ws }
start_bracket  = _{ ws ~ "[" ~ ws }
start_paren    = _{ ws ~ "(" ~ ws }
string         = @{ quote ~ (escaped_char | normal_char)+ ~ quote }
unicode_escape = @{ "\"u\"" ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT ~ ASCII_HEX_DIGIT }
ws             = _{ (" " | "\t" | NEWLINE)* }
